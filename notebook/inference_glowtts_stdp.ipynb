{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from models.glow_tts_with_pitch import GlowTTSModel\n",
    "from utils.data import load_speaker_emb\n",
    "\n",
    "from nemo.collections.tts.models import HifiGanModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def infer(\n",
    "    spec_gen_model,\n",
    "    vocoder_model,\n",
    "    str_input,\n",
    "    noise_scale=0.0,\n",
    "    length_scale=1.0,\n",
    "    speaker=None,\n",
    "    speaker_embeddings=None,\n",
    "    stoch_dur_noise_scale=0.8,\n",
    "    stoch_pitch_noise_scale=1.0,\n",
    "    pitch_scale=0.0,\n",
    "):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        parsed = spec_gen_model.parse(str_input)\n",
    "\n",
    "        spectrogram = spec_gen_model.generate_spectrogram(\n",
    "            tokens=parsed,\n",
    "            noise_scale=noise_scale,\n",
    "            length_scale=length_scale,\n",
    "            speaker=speaker,\n",
    "            speaker_embeddings=speaker_embeddings,\n",
    "            stoch_dur_noise_scale=stoch_dur_noise_scale,\n",
    "            stoch_pitch_noise_scale=stoch_pitch_noise_scale,\n",
    "            pitch_scale=pitch_scale,\n",
    "        )\n",
    "\n",
    "        audio = vocoder_model.convert_spectrogram_to_audio(spec=spectrogram)\n",
    "\n",
    "    if spectrogram is not None:\n",
    "        if isinstance(spectrogram, torch.Tensor):\n",
    "            spectrogram = spectrogram.to(\"cpu\").numpy()\n",
    "        if len(spectrogram.shape) == 3:\n",
    "            spectrogram = spectrogram[0]\n",
    "    if isinstance(audio, torch.Tensor):\n",
    "        audio = audio.to(\"cpu\").numpy()\n",
    "    return spectrogram, audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load glowtts model from checkpoint\n",
    "spec_gen = GlowTTSModel.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "spec_gen = spec_gen.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# load vocoder from checkpoint\n",
    "vocoder = HifiGanModel.load_from_checkpoint(checkpoint).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load speaker embeddings for conditioning\n",
    "speaker_emb_dict = load_speaker_emb(spk_emb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, let's give an input that we want our models to speak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Extract speaker embedding from file\n",
    "\n",
    "audio_path = \"common_voice_en_18498899.wav\"\n",
    "audio_path_wo = audio_path.split(\".\")[0]\n",
    "\n",
    "speaker_embeddings = speaker_emb_dict.get(audio_path_wo)\n",
    "speaker_embeddings = torch.from_numpy(speaker_embeddings).reshape(1, -1).to(device)\n",
    "\n",
    "if speaker_embeddings is None:\n",
    "    print(\"Could not load speaker embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Inference hyperparameters\n",
    "\n",
    "sr=16000\n",
    "noise_scale=0.667\n",
    "length_scale=1.0 #\n",
    "stoch_dur_noise_scale=0.8 #0.0-1.0\n",
    "stoch_pitch_noise_scale=0.8\n",
    "pitch_scale=0.0\n",
    "speaker=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from nemo_text_processing.text_normalization.normalize import Normalizer\n",
    "\n",
    "# initialize normalizer\n",
    "normalizer = Normalizer(input_case=\"cased\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "text_to_generate = \"A look of fear crossed his face, but he regained his serenity immediately.\"\n",
    "\n",
    "# normalize text. necessary in case text contains numeric text, dates, and abbreviations\n",
    "text_to_generate = normalizer.normalize(text_to_generate)\n",
    "print(text_to_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "log_spec, audio = infer(spec_gen, vocoder, text_to_generate, \n",
    "                    noise_scale=noise_scale,\n",
    "                    length_scale=length_scale,\n",
    "                    speaker=speaker,\n",
    "                    stoch_dur_noise_scale=stoch_dur_noise_scale,\n",
    "                    stoch_pitch_noise_scale=stoch_pitch_noise_scale,\n",
    "                    pitch_scale=pitch_scale,\n",
    "                    speaker_embeddings=speaker_embeddings,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ipd.Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
